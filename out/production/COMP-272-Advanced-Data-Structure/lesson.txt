* Any solution to a computational problem, improvements can be made in the following ways.
 * 1. research into the problem and use existing work (that was previously done)
 * 2. algorithmic improvement (clever solution)
 * 3. data structures
 *
 * After this,
 * 4. code level improvement (lot of little things or tricks you can do)
 * 5. (ignoring changing to a faster processor, or more memory)
 * 6. parallelism - which use of multiple cores on your computer

Algorithm analysis:
 - Big-O notation:
    1. records worst-case runtime as a mathematical function
    2. It is also asymptotic (size -> infinity)
    The relationship between input size n and runtime t is captured via O() notation.
    Operations that take units of time: multiplication, div, add, sub, comparison,
    assignment, evaluation a condition (boolean).
    If total time taken is independent of size of input n, then we call it O(1) algorithm (constant).
    For the same problem you can design algorithms with different runtime complexities.
    other examples: O(log(n)), O(n), O(n^2), O(2^n) ...
    examples:
    * outer loop 1 to n {
        inner loop 1 to n {
            simple operations (O(1) time)
        }
     }
        --> n * n = n^2 --> O(n^2) --> quadratic

    * if (X time condition) {
        = A
    } else {
        = B
    }
        --> time complexity of X + time of A or of B
        --> in this case, we take the max between time of A and B.
            --> so: time of X + max time between A and B.

    Some functions in ascending order:
    2/n, 37, sqrt(n), n, n.log(log(n)), n.log(n) (which is equal to n.log(n^2) in big-O notation),
    n.(log(n))^2, n^1.5, n^2, n^2.log(n), n^3, 2^(n/2) (which is the same as 2^(n) in big-O notation